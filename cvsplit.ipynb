{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RluAIcaTEIynBT_ds-graANHhOrdg0SQ",
      "authorship_tag": "ABX9TyPSqF7JEe8mep9Vo5znbEV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Logesh001/OCR/blob/main/cvsplit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pGCJag2l7Ur0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image #PIL(Python Imaging Library)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes an image path, coordinates (to define the region to crop), and a saved location. It opens an image, crops it using the provided coordinates, and saves the cropped image at the specified location.[link text](https://)"
      ],
      "metadata": {
        "id": "0_TCyoiU-Rib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop(image_path, coords, saved_location):\n",
        "    image_obj = Image.open(image_path)\n",
        "    cropped_image = image_obj.crop(coords)\n",
        "    cropped_image.save(saved_location)"
      ],
      "metadata": {
        "id": "F665CXmf7gGd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reads an image named \"para2.jpg\" using OpenCV's cv2.imread.The height and width of the original image are stored as h1 and w1.\n",
        "    A blank white image with dimensions slightly larger than the original image is created using NumPy (blank_image).\n",
        "    The original image is copied onto the blank image with an offset of (11, 11) to give it a margin. The result is stored in the img variable."
      ],
      "metadata": {
        "id": "88FF9JJS-IiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_img = cv2.imread(\"/content/drive/MyDrive/Goodnotes_test/test/eng_AF_027.jpg\")#/content/drive/MyDrive/Goodnotes/train\n",
        "\n",
        "h1,w1 = orig_img.shape[:2]\n",
        "\n",
        "blank_image = np.zeros((h1+20,w1+20,3), np.uint8)\n",
        "blank_image[:,:] = (255,255,255)\n",
        "x_offset = y_offset = 11\n",
        "img = blank_image.copy()\n",
        "img[y_offset:y_offset+h1, x_offset:x_offset+w1] = orig_img.copy()\n",
        "\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "th1,thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_TOZERO_INV)\n",
        "print(f\"threshold1:{th1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDukZ-_k7sVt",
        "outputId": "9eb8016b-81ba-4b33-840e-a2886ebe3d58"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold1:127.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpdAHoEvZzk2",
        "outputId": "cabbc0db-7e1e-49f0-c673-055d8baccfe2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The copied image (img) is converted to grayscale using cv2.cvtColor.A binary inverse threshold is applied to the grayscale image using cv2.threshold. The threshold value is set to 127, and the result is stored in thresh1"
      ],
      "metadata": {
        "id": "9Z0P0yFq_fwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thresholding is a common image processing technique used to **segment an image to different regions** based on their intensity or color of the pixel"
      ],
      "metadata": {
        "id": "nH486LkwJZgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th, threshed = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)\n",
        "print(f\"threshold:{th}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K_0JVtD-jLj",
        "outputId": "f91e03d4-670e-4ddb-e81f-0ca2a9adb091"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold:143.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  The code finds the non-zero points (foreground pixels) in the thresholded image using cv2.findNonZero. The minimum area rectangle is fitted around these points using cv2.minAreaRect, which returns the rectangle's center, size, and angle of rotation."
      ],
      "metadata": {
        "id": "jzAN8jkQGA0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pts = cv2.findNonZero(threshed)\n",
        "ret = cv2.minAreaRect(pts)\n",
        "\n",
        "(cx,cy), (w,h), ang = ret\n",
        "#if w>h:\n",
        " #   w,h = h,w\n",
        " #   ang += 90\n",
        "print(f\"ang:{ang}\")\n",
        "ang = 0\n",
        "th = 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eej6F5hu_0ZN",
        "outputId": "8d2c4202-38ce-4cab-9ded-3cd49f475176"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ang:90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  A rotation matrix (M) is generated using cv2.getRotationMatrix2D to rotate the image by a specified angle around the rectangle's center. The thresholded image is rotated using cv2.warpAffine with the calculated rotation matrix (M).\n",
        "  Histograms are computed along the rows of the rotated and grayscale images using cv2.reduce. These histograms are used to detect upper and lower boundaries of lines in the text."
      ],
      "metadata": {
        "id": "H771PdD9Gj-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
        "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))"
      ],
      "metadata": {
        "id": "JcgFewnRGIc5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  The code processes the histograms to identify the upper and lower boundaries of lines of text.\n",
        "    The upper and lower boundaries are determined by changes in histogram values. If the value transitions from below a threshold (th) to above the threshold or vice versa, it's considered a boundary.\n",
        "    Detected upper and lower boundaries are stored in the uppers and lowers lists."
      ],
      "metadata": {
        "id": "7ZOPyy9_uKBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  The rotated image is converted back to a BGR image using cv2.cvtColor.\n",
        "    Lines representing the upper and lower boundaries are drawn on the rotated image using cv2.line.\n",
        "    For each detected upper and lower boundary pair, the code checks if the distance between them is large enough to indicate a significant block of text. If so, it calculates the coordinates to crop the original image and calls the crop function to save the cropped region."
      ],
      "metadata": {
        "id": "ipQMkDwLuOHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rotated and annotated image is saved as \"result.png\" using cv2.imwrite"
      ],
      "metadata": {
        "id": "225e3OnduY8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
        "hist1 = cv2.reduce(gray,1, cv2.REDUCE_AVG).reshape(-1)\n",
        "\n",
        "# Create function that adds 100 to something\n",
        "sub_255 = lambda i: i - 255\n",
        "# Create vectorized function\n",
        "vectorized_sub_255 = np.vectorize(sub_255)\n",
        "#print(f\"his1:{vectorized_sub_255(hist1)}\")\n",
        "print(f\"hist:{hist}\")\n",
        "print(f\"threshold:{th}\")\n",
        "H,W = img.shape[:2]\n",
        "print(f\"H:{H}\")\n",
        "print(f\"size:{len(hist)}\")\n",
        "uppers = [y-y_offset for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
        "lowers = [y-y_offset for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
        "print(uppers)\n",
        "print(lowers)\n",
        "\n",
        "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "for y in uppers:\n",
        "    cv2.line(rotated, (0,y-15), (W, y-15), (255,0,0), 1)\n",
        "\n",
        "for y in lowers:\n",
        "    cv2.line(rotated, (0,y+15), (W, y+15), (0,255,0), 1)\n",
        "\n",
        "i=0\n",
        "for y in uppers:\n",
        "    upper_y = y\n",
        "    if i >= len(lowers):\n",
        "        continue\n",
        "    lower_y = lowers[i]\n",
        "    i=i+1\n",
        "    print(f\"lower:{lower_y} upper:{upper_y}\")\n",
        "    if (lower_y - upper_y) < 10:\n",
        "        continue\n",
        "    coords = [0,upper_y-15,W,lower_y+15]\n",
        "    crop(\"/content/drive/MyDrive/Goodnotes_test/test/eng_AF_027.jpg\",coords,f\"save{i}.png\")\n",
        "\n",
        "cv2.imwrite(\"result.png\", rotated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGaLqMxkGqVI",
        "outputId": "ae3680be-cb9e-4de5-9f07-2d8e0dec393c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hist:[0 0 0 ... 0 0 0]\n",
            "threshold:10\n",
            "H:1726\n",
            "size:1726\n",
            "[-1, 190, 222, 224, 228, 273, 280, 283, 285, 288, 296, 343, 347, 350, 366, 422, 427, 436, 483, 519, 533, 552, 578, 593, 605, 626, 679, 686, 695, 743]\n",
            "[183, 221, 223, 226, 236, 276, 282, 284, 287, 289, 302, 346, 348, 351, 371, 423, 430, 441, 517, 524, 551, 573, 583, 597, 606, 661, 684, 689, 737, 1705]\n",
            "lower:183 upper:-1\n",
            "lower:221 upper:190\n",
            "lower:223 upper:222\n",
            "lower:226 upper:224\n",
            "lower:236 upper:228\n",
            "lower:276 upper:273\n",
            "lower:282 upper:280\n",
            "lower:284 upper:283\n",
            "lower:287 upper:285\n",
            "lower:289 upper:288\n",
            "lower:302 upper:296\n",
            "lower:346 upper:343\n",
            "lower:348 upper:347\n",
            "lower:351 upper:350\n",
            "lower:371 upper:366\n",
            "lower:423 upper:422\n",
            "lower:430 upper:427\n",
            "lower:441 upper:436\n",
            "lower:517 upper:483\n",
            "lower:524 upper:519\n",
            "lower:551 upper:533\n",
            "lower:573 upper:552\n",
            "lower:583 upper:578\n",
            "lower:597 upper:593\n",
            "lower:606 upper:605\n",
            "lower:661 upper:626\n",
            "lower:684 upper:679\n",
            "lower:689 upper:686\n",
            "lower:737 upper:695\n",
            "lower:1705 upper:743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQ3o9YY1argy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}